#Tpyramid

import cv2
import numpy as np 
img  = cv2.imread("spacex.jpg")
levels = 5
pyramid  = [img]
for _ in range(levels-1):
    img = cv2.pyrDown(img)
    pyramid.append(img)
for i,img in enumerate(pyramid):
    cv2.imshow(f"Levels {i}",img)
cv2.waitKey(0)
cv2.destroyAllWindows()


#Quad tree

import matplotlib.pyplot as plt
import cv2
import numpy as np 
img = cv2.imread("/content/hokage-minato-namikaze-thumb.jpg")
from operator import add
from functools import reduce 
half = np.array_split(img,2)
res = map(lambda x:np.array_split(x,2,axis=1),half)
split = reduce(add,res)
fig,axs = plt.subplots(2,2)
axs[0,0].imshow(split[0])
axs[0,1].imshow(split[1])
axs[1,0].imshow(split[2])
axs[1,1].imshow(split[3])
plt.show()
top = np.concatenate((split[0],split[1]),axis=1)
bottom = np.concatenate((split[2],split[3]),axis=1)
full = np.concatenate((top,bottom),axis=0)
plt.imshow(full)
plt.show()



#Geometric transformation

from google.colab.patches import cv2_imshow
import cv2
import numpy as np
import matplotlib.pyplot as plt
image  = cv2.imread("hokage-minato-namikaze-thumb.jpg")
ide
plt.imshow(image)
plt.show()

rotateMatrix = cv2.getRotationMatrix2D((image.shape[0]/2,image.shape[1]/2),90,1)
rotatedImage = cv2.warpAffine(image,rotateMatrix,(image.shape[0],image.shape[1])) 
cv2_imshow(rotatedImage)
cv2.waitKey(0)
cv2.destroyAllWindows()

scaleImage = cv2.resize(image,None,fx=0.5,fy=0.5)

cv2_imshow(scaleImage)
cv2.waitKey(0)
cv2.destroyAllWindows()

skewMatrix = np.float32([[1,0.2,0],[0.1,1,0]])
skewImage = cv2.warpAffine(image,skewMatrix,(image.shape[0],image.shape[1]))

cv2_imshow(skewImage)
cv2.waitKey(0)
cv2.destroyAllWindows()

affineMatrix = cv2.getAffineTransform(np.float32([[50, 50], [200, 50],[50, 200]]),np.float32([[10, 100],[200, 50], [100, 250]]))
affineImage = cv2.warpAffine(image,affineMatrix,(image.shape[1],image.shape[0]))

cv2_imshow(affineImage)
cv2.waitKey(0)
cv2.destroyAllWindows()

src = np.float32([[100,100],[10,1500],[2600,1500],[2500,250]])
dest = np.float32([[0,500],[500,1600],[2700,100],[2000,5]])

biliearMatrix  = cv2.getPerspectiveTransform(src,dest)
bilinearImage = cv2.warpPerspective(image,biliearMatrix,(image.shape[1],image.shape[0]))

cv2_imshow(bilinearImage)
cv2.waitKey(0)
cv2.destroyAllWindows()





#Object detection

import torch 
from PIL import Image
import cv2 
model = torch.hub.load("ultralytics/yolov5",'yolov5s')
img = Image.open('hokage-minato-namikaze-thumb.jpg')
result = model(img)
result.show()


#Edge detection 

import cv2
from google.colab.patches import cv2_imshow
def motion(path):
    cap = cv2.VideoCapture(path)
    ret,prev_frame = cap.read()
    prev_gray = cv2.cvtColor(prev_frame,cv2.COLOR_BGR2GRAY)
    while cap.isOpened():
        ret,frame = cap.read()
        if not ret: break
        frame_gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)
        edge_prev = cv2.Canny(prev_gray,50,150)
        edge = cv2.Canny(frame_gray,50,150)
        diff = cv2.absdiff(edge_prev,edge)
        cv2_imshow(diff)
        if cv2.waitKey(30)&0xFF == ord('q'):
            break
        prev_gray = frame_gray.copy()
    cap.release()
    cv2.destroyAllWindows()
path="video.mp4"
motion(path)

#event detection

import cv2
cap = cv2.VideoCapture("video.mp4")
bgSubtractor = cv2.createBackgroundSubtractorMOG2()
while cap.isOpened():
    ret,frame = cap.read()
    if not ret :
        break
    mask = bgSubtractor.apply(frame)
    _,threshold = cv2.threshold(mask,50,255,cv2.THRESH_BINARY)
    contours,_ = cv2.findContours(threshold,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)
    for contour in contours:
        if(cv2.contourArea(contour)>100):
            x,y,w,h = cv2.boundingRect(contour)
            cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)
            cv2.imshow('video',frame)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
cap.release()
cv2.destroyAllWindows()


#Face detection

import cv2
from google.colab.patches import cv2_imshow

face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

image = cv2.imread('media/people.jpg')

gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=18, minSize=(30, 30))
names = ['Person A','Person B','Person C','Person D']
i=0
for (x, y, w, h) in faces:
    cv2.rectangle(image, (x, y), (x+w, y+h), (255, 255, 255), 3)
    cv2.putText(image,names[i],(x,y),cv2.FONT_HERSHEY_SIMPLEX,1.3,(255,255,255),4)
    i = i+1

cv2_imshow('Face Detection',image)
cv2.waitKey(0)
cv2.destroyAllWindows()


#line detection
import cv2
import numpy as np
from google.colab.patches import cv2_imshow

image = cv2.imread('/content/img.jpg')
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
blurred = cv2.GaussianBlur(gray, (5, 5), 0)
edges = cv2.Canny(blurred, 50, 150)
lines = cv2.HoughLines(edges, 1, np.pi / 180, 150)
if lines is not None:
    for rho, theta in lines[:, 0]:
        a = np.cos(theta)
        b = np.sin(theta)
        x0 = a * rho
        y0 = b * rho
        x1 = int(x0 + 1000 * (-b))
        y1 = int(y0 + 1000 * (a))
        x2 = int(x0 - 1000 * (-b))
        y2 = int(y0 - 1000 * (a))
        cv2.line(image, (x1, y1), (x2, y2), (0, 0, 255), 2)
cv2_imshow(image)
cv2.waitKey(0)
cv2.destroyAllWindows()

#smoothing

import cv2
from google.colab.patches import cv2_imshow
image = cv2.imread('/content/im.jpg')
plt.imshow(image)
gaussian_blur = cv2.GaussianBlur(image, (5, 5), 0)
median_blur = cv2.medianBlur(image, 5)
cv2_imshow(image)
cv2_imshow(gaussian_blur)
cv2_imshow(median_blur)
cv2.waitKey(0)
cv2.destroyAllWindows()


